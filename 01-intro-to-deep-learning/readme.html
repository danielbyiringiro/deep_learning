<h1>Section 1: What is deep learning and why has it taken off?</h1>
<p>Deep learning is a subset of machine learning which is itself a subset of AI. Specifically, deep learning involves the application of a particular kind of statistical model called neural networks. Neural networks are a model suitable for supervised learning, and they excel at modeling complex relationships in multi-dimensional data. While the algorithmic foundation for modern neural networks was laid in the 1970â€™s it has only recently become mainstream for two reasons. Lack of computational power and lack of large datasets.</p>
<p><strong>By the end of this section students should be able to:</strong></p>
<ul>
<li>Define key machine learning and deep learning terminology.</li>
<li>Describe neural networks as computational graphs and as complex mathematical formulas.</li>
<li>Describe how neural networks are trained at a high level.</li>
<li>Use Tensorflow to build, train, and evaluate simple neural networks.</li>
</ul>
<h2>Part 1: What Are Neural Networks, and Why Now?</h2>
<p>Neural networks have taken off in no small part due to improvements in computing hardware. The first papers describing neural networks were written in the 1970's, but it was 40 years of Moore's Law that made the technique viable. In addition to the increase in computational power and massive improvements in parallel computing, neural networks have benefited from the collection of massive amounts of data.</p>
<p>In this section we'll discuss what neural networks are, the process through which they are trained, what they are good at, and some critical terminology. We'll also try to get past the hype and recognize some of the weaknesses of ML techniques and deep learning in general.</p>
<h3>Pre-reading Material</h3>
<ul>
<li><a href="https://medium.com/tebs-lab/introduction-to-deep-learning-a46e92cb0022">Introduction to Deep Learning</a></li>
<li><a href="https://medium.com/tebs-lab/deep-neural-networks-as-computational-graphs-867fcaa56c9">Neural Networks as Computational Graphs</a></li>
</ul>
<h3>Resources for Further Exploration</h3>
<ul>
<li><a href="http://neuralnetworksanddeeplearning.com/chap4.html">Deep Learning Book, Chapter 4: Universal Approximation Theorem</a></li>
<li><a href="http://scott.fortmann-roe.com/docs/BiasVariance.html">The Bias/Variance Tradeoff</a></li>
<li><a href="https://towardsdatascience.com/why-deep-learning-is-needed-over-traditional-machine-learning-1b6a99177063">Why Deep Learning Over Traditional Machine Learning</a></li>
<li><a href="https://www.technologyreview.com/s/612768/we-analyzed-16625-papers-to-figure-out-where-ai-is-headed-next/">Historical Trends in AI/ML/Deep Learning</a></li>
<li><a href="https://medium.com/tebs-lab/the-age-of-parallel-computing-b3f4319c97b0">High Performance Computing is More Parallel Than Ever</a></li>
<li><a href="https://openai.com/blog/ai-and-compute/">OpenAI: AI and Compute</a></li>
<li><a href="https://towardsdatascience.com/hacking-neural-networks-2b9f461ffe0b">Neural Networks Are Hackable</a></li>
</ul>
<h2>Part 2: Building Neural Networks With Keras</h2>
<p>Theory is great, but putting the theory into practice is more practical. In this section we'll build a handful of simple neural networks using the Keras library.</p>
<h3>Pre-Reading Material</h3>
<ul>
<li><a href="https://medium.com/tebs-lab/how-to-classify-mnist-digits-with-different-neural-network-architectures-39c75a0f03e3">Classifying MNIST Digits With Keras</a></li>
</ul>
<h3>Helpful Documentation</h3>
<ul>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/">Tensorflow Main Python Docs</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/keras">TF Keras Frontend Docs</a></li>
<li><a href="https://matplotlib.org/">Matplotlib docs</a></li>
</ul>
<h2>Part 3: Exploring Neural Network Architectures</h2>
<p>Neural networks are very flexible models. The architecture of individual networks has a dramatic impact on their performance. Different architectures might be better suited to different tasks. Much of the ongoing research into neural networks is related to creating new architectures that out-perform the existing state of the art.</p>
<p>In this section we'll explore some of the impacts of different network architectures by constructing a few networks with different architectures.</p>
<h3>Pre-Reading Material</h3>
<ul>
<li><a href="https://www.heatonresearch.com/2017/06/01/hidden-layers.html">Picking The Number of Hidden Layers</a></li>
</ul>
<h3>Resources For Further Exploration</h3>
<ul>
<li><a href="https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/">How To Configure The Number of Nodes and Layers in a Neural Network</a></li>
<li><a href="https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw">Stack Exchange Discussion on Choosing Number of Nodes and Layers</a></li>
<li><a href="https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464">List of Neural Network Topologies</a></li>
<li><a href="https://www.asimovinstitute.org/neural-network-zoo/">Asimov Institute's "Neural Network Zoo", another great collection of different types of network architectures</a></li>
</ul>